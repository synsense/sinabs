{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samurai2077/anaconda3/envs/speck-rescnn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "from sinabs.backend.dynapcnn import DVSLayer\n",
    "from sinabs.layers import Merge, IAFSqueeze, SumPool2d\n",
    "from sinabs.activation.surrogate_gradient_fn import PeriodicExponential\n",
    "import sinabs.layers as sl\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from tonic.datasets.nmnist import NMNIST\n",
    "from tonic.transforms import ToFrame\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "height = 34\n",
    "width = 34\n",
    "batch_size = 1\n",
    "\n",
    "input_shape = (channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "  (iaf1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  (iaf2): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (conv3): Conv2d(10, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "  (iaf3): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (fc1): Linear(in_features=144, out_features=200, bias=False)\n",
       "  (iaf4): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (fc2): Linear(in_features=200, out_features=10, bias=False)\n",
       "  (iaf5): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "  tensor(1.), min_v_mem=Parameter containing:\n",
       "  tensor(-1.), batch_size=1, num_timesteps=-1)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_shape) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # -- chip core A --\n",
    "        self.conv1 = nn.Conv2d(1, 10, 2, 1, bias=False)\n",
    "        self.iaf1 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())\n",
    "        self.pool1 = nn.AvgPool2d(2,2)\n",
    "        # -- chip core B --\n",
    "        self.conv2 = nn.Conv2d(10, 10, 4, 1, bias=False)\n",
    "        self.iaf2 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())\n",
    "        # -- chip core C --\n",
    "        self.conv3 = nn.Conv2d(10, 1, 2, 1, bias=False)\n",
    "        self.iaf3 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())\n",
    "        # -- chip core D --\n",
    "        self.fc1 = nn.Linear(144, 200, bias=False)\n",
    "        self.iaf4 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())\n",
    "        # -- chip core E --\n",
    "        self.fc2 = nn.Linear(200, 10, bias=False)\n",
    "        self.iaf5 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())\n",
    "\n",
    "        # -- layers ignored during deployment --\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, layer in self.named_modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_normal_(layer.weight.data)\n",
    "\n",
    "    def detach_neuron_states(self):\n",
    "        for name, layer in self.named_modules():\n",
    "            if name != '':\n",
    "                if isinstance(layer, sl.StatefulLayer):\n",
    "                    for name, buffer in layer.named_buffers():\n",
    "                        buffer.detach_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        con1_out = self.conv1(x) # 4\n",
    "        iaf1_out = self.iaf1(con1_out) # 5\n",
    "        pool1_out = self.pool1(iaf1_out) # 6\n",
    "\n",
    "        conv2_out = self.conv2(pool1_out) # 7\n",
    "        iaf2_out = self.iaf2(conv2_out) # 8\n",
    "\n",
    "        conv3_out = self.conv3(iaf2_out) # 9\n",
    "        iaf3_out = self.iaf3(conv3_out) # 10\n",
    "\n",
    "        flat_out = self.flat(iaf3_out) # 15\n",
    "        \n",
    "        fc1_out = self.fc1(flat_out) # 11\n",
    "        iaf4_out = self.iaf4(fc1_out) # 12\n",
    "        fc2_out = self.fc2(iaf4_out) # 13\n",
    "        iaf5_out = self.iaf5(fc2_out) # 14\n",
    "\n",
    "        return iaf5_out\n",
    "    \n",
    "snn = SNN(input_shape)\n",
    "snn.init_weights()\n",
    "snn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "hw_model = DynapcnnNetwork(\n",
    "    snn=snn,\n",
    "    input_shape=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    dvs_input=True,\n",
    "    discretize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network is valid\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'speck2fdevkit:0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhw_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeck2fdevkit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/sinabs/sinabs/backend/dynapcnn/dynapcnn_network.py:302\u001b[0m, in \u001b[0;36mDynapcnnNetwork.to\u001b[0;34m(self, device, monitor_layers, config_modifier, slow_clk_frequency, layer2core_map, chip_layers_ordering)\u001b[0m\n\u001b[1;32m    293\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_config(\n\u001b[1;32m    294\u001b[0m     layer2core_map\u001b[38;5;241m=\u001b[39mlayer2core_map,\n\u001b[1;32m    295\u001b[0m     chip_layers_ordering\u001b[38;5;241m=\u001b[39mchip_layers_ordering,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m     config_modifier\u001b[38;5;241m=\u001b[39mconfig_modifier,\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# apply configuration to device.\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamna_device \u001b[38;5;241m=\u001b[39m \u001b[43mopen_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamna_device\u001b[38;5;241m.\u001b[39mget_model()\u001b[38;5;241m.\u001b[39mapply_configuration(config)\n\u001b[1;32m    304\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Github/sinabs/sinabs/backend/dynapcnn/io.py:255\u001b[0m, in \u001b[0;36mopen_device\u001b[0;34m(device_id)\u001b[0m\n\u001b[1;32m    253\u001b[0m device_id \u001b[38;5;241m=\u001b[39m standardize_device_id(device_id\u001b[38;5;241m=\u001b[39mdevice_id)\n\u001b[1;32m    254\u001b[0m device_map \u001b[38;5;241m=\u001b[39m get_device_map()\n\u001b[0;32m--> 255\u001b[0m device_info \u001b[38;5;241m=\u001b[39m \u001b[43mdevice_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    256\u001b[0m device_handle \u001b[38;5;241m=\u001b[39m samna\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mopen_device(device_info)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'speck2fdevkit:0'"
     ]
    }
   ],
   "source": [
    "hw_model.to(device=\"speck2fdevkit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
