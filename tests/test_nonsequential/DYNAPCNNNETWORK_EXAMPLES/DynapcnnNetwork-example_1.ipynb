{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "from sinabs.layers import Merge, IAFSqueeze, SumPool2d\n",
    "from sinabs.activation.surrogate_gradient_fn import PeriodicExponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8bfc4ebad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "channels = 2\n",
    "height = 34\n",
    "width = 34\n",
    "batch_size = 8\n",
    "\n",
    "input_shape = (channels, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Module\n",
    "\n",
    "We need to define a `nn.Module` implementing the network we want the chip to reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 10, 2, 1, bias=False) # node 0\n",
    "        self.iaf1 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())            # node 1\n",
    "        self.pool1 = nn.AvgPool2d(3,3)                  # node 2\n",
    "        self.pool1a = nn.AvgPool2d(4,4)                 # node 3\n",
    "\n",
    "        self.conv2 = nn.Conv2d(10, 10, 4, 1, bias=False)# node 4\n",
    "        self.iaf2 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())            # node 6\n",
    "\n",
    "        self.conv3 = nn.Conv2d(10, 1, 2, 1, bias=False) # node 8\n",
    "        self.iaf3 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())            # node 9\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(49, 500, bias=False)       # node 10\n",
    "        self.iaf4 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())            # node 11\n",
    "        \n",
    "        self.fc2 = nn.Linear(500, 10, bias=False)       # node 12\n",
    "        self.iaf5 = IAFSqueeze(batch_size=batch_size, min_v_mem=-1.0, spike_threshold=1.0, surrogate_grad_fn=PeriodicExponential())            # node 13\n",
    "\n",
    "        self.adder = Merge()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        con1_out = self.conv1(x)\n",
    "        iaf1_out = self.iaf1(con1_out)\n",
    "        pool1_out = self.pool1(iaf1_out)\n",
    "        pool1a_out = self.pool1a(iaf1_out)\n",
    "\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        iaf2_out = self.iaf2(conv2_out)\n",
    "\n",
    "        conv3_out = self.conv3(self.adder(pool1a_out, iaf2_out))\n",
    "        iaf3_out = self.iaf3(conv3_out)\n",
    "\n",
    "        flat_out = self.flat(iaf3_out)\n",
    "        \n",
    "        fc1_out = self.fc1(flat_out)\n",
    "        iaf4_out = self.iaf4(fc1_out)\n",
    "        fc2_out = self.fc2(iaf4_out)\n",
    "        iaf5_out = self.iaf5(fc2_out)\n",
    "\n",
    "        return iaf5_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "snn = SNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DynapcnnNetwork Class\n",
    "\n",
    "In the constructor of `DynapcnnNetworkGraph` the SNN passed as argument (defined as a `nn.Module`) will be parsed such that each layer is represented in a computational graph (using `nirtorch.extract_torch_graph`). \n",
    "\n",
    "The layers are the `nodes` of the graph, while their connectivity (how the outputs from a layer are sent to other layers) is represented as `edges`, represented in a `list` of `tuples`.\n",
    "\n",
    "Once the constructor finishes its initialization, the `hw_model.dynapcnn_layers` property is a dictionary where each entry represents the ID of a `DynapcnnLayer` instance (an `int` from `0` to `L`), with this entry containing a `DynapcnnLayer` instance where a subset of the layers in the original SNN has been incorporated into, the core such instance has been assigned to, and the list of `DynapcnnLayer` instances (their IDs) the layer targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "hw_model = DynapcnnNetwork(\n",
    "    snn=snn,\n",
    "    input_shape=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    discretize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the model bellow how the property <code>DynapcnnLayer</code> in the model has yet to be assigned to a core. This is only done once\n",
    "<code>DynapcnnNetworkGraph.to()</code> is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- [ DynapcnnLayer 0 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 0): Conv2d(2, 10, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "(node 1): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "(node 2): SumPool2d(norm_type=1, kernel_size=(3, 3), stride=None, ceil_mode=False)\n",
      "(node 3): SumPool2d(norm_type=1, kernel_size=(4, 4), stride=None, ceil_mode=False)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: True\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: None\n",
      "> destination DynapcnnLayers: [1, 2]\n",
      "> node 2 feeds input to nodes [4]\n",
      "> node 3 feeds input to nodes [7]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 1 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 4): Conv2d(10, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "(node 6): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: 4.5\n",
      "> assigned core index: None\n",
      "> destination DynapcnnLayers: [2]\n",
      "> node 6 feeds input to nodes [7]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 2 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 7): Conv2d(10, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "(node 8): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: 8.0\n",
      "> assigned core index: None\n",
      "> destination DynapcnnLayers: [3]\n",
      "> node 8 feeds input to nodes [9]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 3 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 9): Conv2d(1, 500, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "(node 10): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: None\n",
      "> destination DynapcnnLayers: [4]\n",
      "> node 10 feeds input to nodes [11]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 4 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 11): Conv2d(500, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "(node 12): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: None\n",
      "> destination DynapcnnLayers: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hw_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hw_model.to()` call will figure out into which core each `DynapcnnLayer` instance will be assigned to. Once this assingment is made the instance itself is used to configure the `CNNLayerConfig` instance representing the core's configuration assigned to it.\n",
    "\n",
    "If the call is sucessfull, the layers comprising the network and their associated metadata will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network is valid: \n",
      "\n",
      "----------------------- [ DynapcnnLayer 0 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 0): Conv2d(2, 10, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "(node 1): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "(node 2): SumPool2d(norm_type=1, kernel_size=(3, 3), stride=None, ceil_mode=False)\n",
      "(node 3): SumPool2d(norm_type=1, kernel_size=(4, 4), stride=None, ceil_mode=False)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: True\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: 0\n",
      "> destination DynapcnnLayers: [1, 2]\n",
      "> node 2 feeds input to nodes [4]\n",
      "> node 3 feeds input to nodes [7]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 1 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 4): Conv2d(10, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "(node 6): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: 4.5\n",
      "> assigned core index: 1\n",
      "> destination DynapcnnLayers: [2]\n",
      "> node 6 feeds input to nodes [7]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 2 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 7): Conv2d(10, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "(node 8): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: 8.0\n",
      "> assigned core index: 2\n",
      "> destination DynapcnnLayers: [3]\n",
      "> node 8 feeds input to nodes [9]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 3 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 9): Conv2d(1, 500, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "(node 10): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: 3\n",
      "> destination DynapcnnLayers: [4]\n",
      "> node 10 feeds input to nodes [11]\n",
      "\n",
      "----------------------- [ DynapcnnLayer 4 ] -----------------------\n",
      "\n",
      "COMPUTATIONAL NODES:\n",
      "\n",
      "(node 11): Conv2d(500, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "(node 12): IAFSqueeze(spike_threshold=Parameter containing:\n",
      "tensor(1.), min_v_mem=Parameter containing:\n",
      "tensor(-1.), batch_size=8, num_timesteps=-1)\n",
      "\n",
      "METADATA:\n",
      "\n",
      "> network's entry point: False\n",
      "> convolution's weight re-scaling factor: None\n",
      "> assigned core index: 4\n",
      "> destination DynapcnnLayers: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hw_model.to(device=\"speck2fmodule:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above now how the layers of the model have been assigned to a chip core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the HW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('device: ', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from train_test_fn import training_loop, load_dataset, split_train_validation, load_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 4\n",
    "epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "n_time_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 34, 2)\n"
     ]
    }
   ],
   "source": [
    "snn_train_dataset, snn_test_dataset, sensor_size, nb_classes = load_dataset('NMNIST', n_time_steps, \"../NMNIST\")\n",
    "\n",
    "print(sensor_size)\n",
    "\n",
    "snn_train_dataloader = DataLoader(snn_train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(hw_model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c30996c7164a019d9a9b26397a4a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5eda68753c4950af5fe79775a9c059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epochs_x, epochs_y, epochs_acc \u001b[38;5;241m=\u001b[39m training_loop(\n\u001b[1;32m      2\u001b[0m     device, \n\u001b[1;32m      3\u001b[0m     n_time_steps,\n\u001b[1;32m      4\u001b[0m     batch_size,\n\u001b[1;32m      5\u001b[0m     sensor_size,\n\u001b[1;32m      6\u001b[0m     snn_train_dataloader, \n\u001b[1;32m      7\u001b[0m     hw_model, \n\u001b[1;32m      8\u001b[0m     loss_fn, \n\u001b[1;32m      9\u001b[0m     optimizer, \n\u001b[1;32m     10\u001b[0m     epochs, \n\u001b[1;32m     11\u001b[0m     snn_test_dataloader)\n",
      "File \u001b[0;32m~/Documents/github/sinabs/tests/test_nonsequential/DYNAPCNNNETWORK_EXAMPLES/../utils/train_test_fn.py:132\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(device, nb_time_steps, batch_size, feature_map_size, dataloader_train, model, loss_fn, optimizer, epochs, dataloader_test)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# gradient update\u001b[39;00m\n\u001b[1;32m    131\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 132\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    133\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# detach the neuron states and activations from current computation graph(necessary)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_x, epochs_y, epochs_acc = training_loop(\n",
    "    device, \n",
    "    n_time_steps,\n",
    "    batch_size,\n",
    "    sensor_size,\n",
    "    snn_train_dataloader, \n",
    "    hw_model, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    epochs, \n",
    "    snn_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speck-rescnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
